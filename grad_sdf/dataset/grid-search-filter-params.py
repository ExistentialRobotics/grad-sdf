import os
from pathlib import Path
import json

import numpy as np
import open3d as o3d
import torch
from pytorch3d.ops import knn_points
from scipy.spatial import cKDTree
from tqdm import tqdm

# è®¾ç½®è·¯å¾„
data_dir = Path("/home/qihao/workplace/grad-sdf/data/newercollege-lidar")
ply_dir = data_dir / "ply"
poses_file = data_dir / "poses.txt"
gt_pointcloud_file = data_dir / "gt-pointcloud.ply"

# æ£€æµ‹GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

# æ–¹æ³•1çš„å›ºå®šå‚æ•°
distance_threshold_method1 = 0.1

# æ–¹æ³•2çš„å‚æ•°æœç´¢ç©ºé—´
param_grid = {
    "distance_threshold": [0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10, 0.12, 0.15],
    "n_neighbors": [2, 3, 4, 5, 6, 8, 10],
}

print("æ­£åœ¨è¯»å–ground truthç‚¹äº‘...")
gt_pcd = o3d.io.read_point_cloud(str(gt_pointcloud_file))
gt_points = np.asarray(gt_pcd.points)
print(f"Ground truthç‚¹äº‘æœ‰ {len(gt_points)} ä¸ªç‚¹")

# ä½¿ç”¨scipyçš„cKDTreeï¼ˆå¯¹å¤§ç‚¹äº‘æ›´å¿«ï¼‰
print(f"æ­£åœ¨æ„å»ºGTç‚¹äº‘çš„cKDTree...")
gt_kdtree = cKDTree(gt_points)
print(f"âœ“ GT cKDTreeå·²å‡†å¤‡å¥½")

# è¯»å–æ‰€æœ‰poses
print("æ­£åœ¨è¯»å–poses...")
with open(poses_file, "r") as f:
    lines = f.readlines()

poses = []
for line in lines:
    if not line.strip():
        continue
    values = list(map(float, line.strip().split()))
    if len(values) == 16:
        matrix = np.array(values).reshape(4, 4)
        poses.append(matrix)

print(f"è¯»å–äº† {len(poses)} ä¸ªposes")

# é€‰æ‹©æµ‹è¯•æ–‡ä»¶
ply_files = sorted(ply_dir.glob("*.ply"))
test_indices = [500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400]
test_files = [ply_files[i] for i in test_indices]
print(f"å°†ä½¿ç”¨ {len(test_files)} ä¸ªæ–‡ä»¶è¿›è¡Œå‚æ•°æœç´¢ï¼ˆç´¢å¼•: {test_indices}ï¼‰")

# é¢„è®¡ç®—æ–¹æ³•1çš„ç»“æœï¼ˆæ‰€æœ‰å‚æ•°ç»„åˆéƒ½ä¸€æ ·ï¼‰
print("\né¢„è®¡ç®—æ–¹æ³•1çš„è¿‡æ»¤ç»“æœ...")
method1_results = []

for i, ply_file in enumerate(tqdm(test_files, desc="è®¡ç®—æ–¹æ³•1")):
    local_pcd = o3d.io.read_point_cloud(str(ply_file))
    local_points = np.asarray(local_pcd.points)

    if len(local_points) == 0:
        method1_results.append(None)
        continue

    # è·å–å¯¹åº”çš„pose
    actual_index = test_indices[i]
    pose = poses[actual_index]

    # è½¬æ¢åˆ°ä¸–ç•Œåæ ‡ç³»
    local_points_homo = np.hstack([local_points, np.ones((len(local_points), 1))])
    world_points_homo = (pose @ local_points_homo.T).T
    world_points = world_points_homo[:, :3]

    # ä½¿ç”¨scipyçš„cKDTreeæŸ¥è¯¢æœ€è¿‘è·ç¦»ï¼ˆå¯¹å¤§ç‚¹äº‘æ›´å¿«ï¼‰
    distances, _ = gt_kdtree.query(world_points, k=1)

    method1_valid_mask = distances <= distance_threshold_method1

    method1_results.append({"local_points": local_points, "valid_mask": method1_valid_mask})

# ç½‘æ ¼æœç´¢
print("\nå¼€å§‹ç½‘æ ¼æœç´¢...")
best_params = None
best_score = -1
all_results = []

total_combinations = len(param_grid["distance_threshold"]) * len(param_grid["n_neighbors"])
pbar = tqdm(total=total_combinations, desc="å‚æ•°æœç´¢")

for dist_thresh in param_grid["distance_threshold"]:
    for n_neighbors in param_grid["n_neighbors"]:
        # å¯¹æ¯ä¸ªå‚æ•°ç»„åˆè®¡ç®—æ–¹æ³•2çš„ç»“æœ
        agreement_rates = []
        total_points = 0
        both_filtered = 0
        only_method1 = 0
        only_method2 = 0
        method1_filtered_total = 0
        method2_filtered_total = 0

        for i, result in enumerate(method1_results):
            if result is None:
                continue

            local_points = result["local_points"]
            method1_valid_mask = result["valid_mask"]

            # æ–¹æ³•2: frameå†…éƒ¨ç‚¹äº‘æ¯”è¾ƒ (ä½¿ç”¨PyTorch3DåŠ é€Ÿ)
            local_points_torch = torch.from_numpy(local_points).float().unsqueeze(0).to(device)  # [1, N, 3]

            # æœç´¢kä¸ªæœ€è¿‘é‚»ï¼ˆåŒ…æ‹¬è‡ªå·±ï¼‰
            knn_result = knn_points(local_points_torch, local_points_torch, K=n_neighbors)
            # dists: [1, N, K], ç¬¬ä¸€ä¸ªæ˜¯è‡ªå·±ï¼ˆè·ç¦»ä¸º0ï¼‰ï¼Œåé¢æ˜¯æœ€è¿‘é‚»
            dists = knn_result.dists[0].cpu().numpy()  # [N, K]

            # è®¡ç®—å¹³å‡è·ç¦»ï¼ˆæ’é™¤è‡ªå·±ï¼Œå³ä»ç´¢å¼•1å¼€å§‹ï¼‰
            avg_distances = np.mean(np.sqrt(dists[:, 1:]), axis=1)  # [N]

            # è®¡ç®—æ¯ä¸ªç‚¹çš„æ·±åº¦ï¼ˆåœ¨ç›¸æœºåæ ‡ç³»ä¸‹ï¼Œå°±æ˜¯åˆ°åŸç‚¹çš„è·ç¦»ï¼‰
            depths = np.linalg.norm(local_points, axis=1)  # [N]

            # æ·±åº¦è‡ªé€‚åº”é˜ˆå€¼ï¼šè¿œå¤„çš„ç‚¹ä½¿ç”¨æ›´å¤§çš„é˜ˆå€¼
            adaptive_thresholds = depths / 10.0 * dist_thresh  # [N]
            method2_valid_mask = avg_distances <= adaptive_thresholds

            # è®¡ç®—ä¸€è‡´æ€§
            method1_filtered_mask = ~method1_valid_mask
            method2_filtered_mask = ~method2_valid_mask

            agreement = np.sum(method1_valid_mask == method2_valid_mask) / len(local_points)
            agreement_rates.append(agreement)

            total_points += len(local_points)
            both_filtered += np.sum(method1_filtered_mask & method2_filtered_mask)
            only_method1 += np.sum(method1_filtered_mask & ~method2_filtered_mask)
            only_method2 += np.sum(~method1_filtered_mask & method2_filtered_mask)
            method1_filtered_total += np.sum(method1_filtered_mask)
            method2_filtered_total += np.sum(method2_filtered_mask)

        # è®¡ç®—è¯„åˆ†æŒ‡æ ‡
        avg_agreement = np.mean(agreement_rates)
        std_agreement = np.std(agreement_rates)

        # è®¡ç®—è¿‡æ»¤ç‡
        method1_filter_rate = method1_filtered_total / total_points
        method2_filter_rate = method2_filtered_total / total_points
        filter_rate_diff = abs(method1_filter_rate - method2_filter_rate)

        # å…³é”®æŒ‡æ ‡ï¼š
        # Recall (å¬å›ç‡): æ–¹æ³•äºŒæ‰¾åˆ°äº†å¤šå°‘æ–¹æ³•ä¸€è¿‡æ»¤çš„ç‚¹
        recall = both_filtered / method1_filtered_total if method1_filtered_total > 0 else 0

        # Precision (ç²¾ç¡®ç‡): æ–¹æ³•äºŒè¿‡æ»¤çš„ç‚¹ä¸­æœ‰å¤šå°‘æ˜¯æ­£ç¡®çš„ï¼ˆå³æ–¹æ³•ä¸€ä¹Ÿè¿‡æ»¤çš„ï¼‰
        precision = both_filtered / method2_filtered_total if method2_filtered_total > 0 else 0

        # False Positive Rate: æ–¹æ³•äºŒè¯¯è¿‡æ»¤çš„ç‚¹çš„æ¯”ä¾‹
        false_positive_rate = only_method2 / total_points

        # F1-score: å¬å›ç‡å’Œç²¾ç¡®ç‡çš„è°ƒå’Œå¹³å‡
        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

        # ç»¼åˆè¯„åˆ†ï¼šä¸»è¦ç›®æ ‡æ˜¯å¬å›ç‡é«˜ï¼Œæ¬¡è¦ç›®æ ‡æ˜¯è¯¯æŠ¥ç‡ä½
        # ä½¿ç”¨åŠ æƒç»„åˆï¼šä¼˜å…ˆè€ƒè™‘å¬å›ç‡ï¼Œç„¶åæƒ©ç½šè¯¯æŠ¥
        score = recall - 1.0 * false_positive_rate

        all_results.append(
            {
                "distance_threshold": dist_thresh,
                "n_neighbors": n_neighbors,
                "avg_agreement": avg_agreement,
                "std_agreement": std_agreement,
                "score": score,
                "recall": recall,
                "precision": precision,
                "f1_score": f1_score,
                "false_positive_rate": false_positive_rate,
                "method1_filter_rate": method1_filter_rate,
                "method2_filter_rate": method2_filter_rate,
                "filter_rate_diff": filter_rate_diff,
                "both_filtered": both_filtered,
                "only_method1": only_method1,
                "only_method2": only_method2,
                "method1_filtered_total": method1_filtered_total,
                "method2_filtered_total": method2_filtered_total,
                "total_points": total_points,
            }
        )

        if score > best_score:
            best_score = score
            best_params = {"distance_threshold": dist_thresh, "n_neighbors": n_neighbors}

        pbar.update(1)

pbar.close()

# æŒ‰è¯„åˆ†æ’åº
all_results.sort(key=lambda x: x["score"], reverse=True)

# ä¿å­˜å®Œæ•´çš„JSONç»“æœï¼ˆæ–¹ä¾¿åç»­é‡æ–°è¯„åˆ†ï¼‰
json_output_file = data_dir / "param_search_raw_results.json"
print(f"\næ­£åœ¨ä¿å­˜å®Œæ•´ç»“æœåˆ° {json_output_file}...")


# è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹ä»¥ä¾¿JSONåºåˆ—åŒ–
def convert_to_serializable(obj):
    """é€’å½’è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹"""
    if isinstance(obj, dict):
        return {key: convert_to_serializable(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_to_serializable(item) for item in obj]
    elif isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    else:
        return obj


serializable_results = convert_to_serializable(all_results)

with open(json_output_file, "w", encoding="utf-8") as f:
    json.dump(serializable_results, f, indent=2, ensure_ascii=False)
print(f"âœ“ å®Œæ•´ç»“æœå·²ä¿å­˜ï¼ˆ{len(all_results)} ç»„å‚æ•°ï¼‰")

# è¾“å‡ºç»“æœ
print("\n" + "=" * 110)
print("å‚æ•°æœç´¢ç»“æœ - Top 15")
print("=" * 110)
print(
    f"{'æ’å':<6} {'è·ç¦»é˜ˆå€¼':<12} {'é‚»å±…æ•°':<8} {'è¯„åˆ†':<12} "
    f"{'å¬å›ç‡':<12} {'ç²¾ç¡®ç‡':<12} {'F1':<12} {'è¯¯æŠ¥ç‡':<12}"
)
print("-" * 110)

for rank, result in enumerate(all_results[:15], 1):
    print(
        f"{rank:<6} {result['distance_threshold']:<12.2f} {result['n_neighbors']:<8} "
        f"{result['score']:<12.4f} "
        f"{result['recall']*100:>10.2f}%  {result['precision']*100:>10.2f}%  "
        f"{result['f1_score']*100:>10.2f}%  {result['false_positive_rate']*100:>10.2f}%"
    )

print("\n" + "=" * 110)
print("ğŸ¯ æœ€ä½³å‚æ•°é…ç½®:")
print("=" * 110)
best_result = all_results[0]
print(f"distance_threshold_method2 = {best_result['distance_threshold']:.2f}")
print(f"n_neighbors = {best_result['n_neighbors']}")

print(f"\nğŸ“Š æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡:")
print(f"  ç»¼åˆè¯„åˆ†: {best_result['score']:.4f}")
print(f"  å¬å›ç‡ (Recall): {best_result['recall']*100:.2f}%  <- æ–¹æ³•äºŒæ‰¾åˆ°äº†æ–¹æ³•ä¸€è¿‡æ»¤ç‚¹çš„æ¯”ä¾‹")
print(f"  ç²¾ç¡®ç‡ (Precision): {best_result['precision']*100:.2f}%  <- æ–¹æ³•äºŒè¿‡æ»¤çš„ç‚¹ä¸­æ­£ç¡®çš„æ¯”ä¾‹")
print(f"  F1-Score: {best_result['f1_score']*100:.2f}%")
print(f"  è¯¯æŠ¥ç‡: {best_result['false_positive_rate']*100:.2f}%  <- æ–¹æ³•äºŒè¯¯è¿‡æ»¤çš„ç‚¹çš„æ¯”ä¾‹")
print(f"  ä¸€è‡´æ€§: {best_result['avg_agreement']*100:.2f}% (Â±{best_result['std_agreement']*100:.2f}%)")

print(f"\nğŸ“ˆ è¯¦ç»†ç»Ÿè®¡:")
print(f"  æ€»ç‚¹æ•°: {best_result['total_points']}")
print(f"  æ–¹æ³•1è¿‡æ»¤ç‚¹æ•°: {best_result['method1_filtered_total']} ({best_result['method1_filter_rate']*100:.2f}%)")
print(f"  æ–¹æ³•2è¿‡æ»¤ç‚¹æ•°: {best_result['method2_filtered_total']} ({best_result['method2_filter_rate']*100:.2f}%)")
print(
    f"\n  âœ… ä¸¤ç§æ–¹æ³•éƒ½è¿‡æ»¤ (æ­£ç¡®): {best_result['both_filtered']} ({best_result['both_filtered']/best_result['total_points']*100:.2f}%)"
)
print(
    f"  âš ï¸  åªè¢«æ–¹æ³•1è¿‡æ»¤ (æ¼æ£€): {best_result['only_method1']} ({best_result['only_method1']/best_result['total_points']*100:.2f}%)"
)
print(
    f"  âŒ åªè¢«æ–¹æ³•2è¿‡æ»¤ (è¯¯æŠ¥): {best_result['only_method2']} ({best_result['only_method2']/best_result['total_points']*100:.2f}%)"
)

print(f"\nğŸ’¡ è§£è¯»:")
if best_result["recall"] > 0.95:
    print(f"  âœ“ å¬å›ç‡å¾ˆé«˜ ({best_result['recall']*100:.1f}%)ï¼Œæ–¹æ³•äºŒèƒ½æ‰¾åˆ°å‡ ä¹æ‰€æœ‰æ–¹æ³•ä¸€è¿‡æ»¤çš„ç‚¹")
elif best_result["recall"] > 0.85:
    print(f"  âœ“ å¬å›ç‡è¾ƒé«˜ ({best_result['recall']*100:.1f}%)ï¼Œæ–¹æ³•äºŒèƒ½æ‰¾åˆ°å¤§éƒ¨åˆ†æ–¹æ³•ä¸€è¿‡æ»¤çš„ç‚¹")
else:
    print(f"  âœ— å¬å›ç‡åä½ ({best_result['recall']*100:.1f}%)ï¼Œæ–¹æ³•äºŒæ¼æ£€äº†è¾ƒå¤šç‚¹")

if best_result["false_positive_rate"] < 0.01:
    print(f"  âœ“ è¯¯æŠ¥ç‡å¾ˆä½ ({best_result['false_positive_rate']*100:.1f}%)ï¼Œæ–¹æ³•äºŒå¾ˆå°‘è¯¯è¿‡æ»¤")
elif best_result["false_positive_rate"] < 0.05:
    print(f"  âœ“ è¯¯æŠ¥ç‡è¾ƒä½ ({best_result['false_positive_rate']*100:.1f}%)ï¼Œæ–¹æ³•äºŒè¯¯è¿‡æ»¤è¾ƒå°‘")
else:
    print(f"  âœ— è¯¯æŠ¥ç‡åé«˜ ({best_result['false_positive_rate']*100:.1f}%)ï¼Œæ–¹æ³•äºŒè¿‡æ»¤äº†è¾ƒå¤šä¸è¯¥è¿‡æ»¤çš„ç‚¹")

# ä¿å­˜å®Œæ•´ç»“æœåˆ°æ–‡ä»¶
output_file = data_dir / "param_search_results.txt"
with open(output_file, "w") as f:
    f.write("å®Œæ•´å‚æ•°æœç´¢ç»“æœ\n")
    f.write("=" * 110 + "\n")
    f.write(
        f"{'æ’å':<6} {'è·ç¦»é˜ˆå€¼':<12} {'é‚»å±…æ•°':<8} {'è¯„åˆ†':<12} "
        f"{'å¬å›ç‡':<12} {'ç²¾ç¡®ç‡':<12} {'F1':<12} {'è¯¯æŠ¥ç‡':<12}\n"
    )
    f.write("-" * 110 + "\n")
    for rank, result in enumerate(all_results, 1):
        f.write(
            f"{rank:<6} {result['distance_threshold']:<12.2f} {result['n_neighbors']:<8} "
            f"{result['score']:<12.4f} "
            f"{result['recall']*100:>10.2f}%  {result['precision']*100:>10.2f}%  "
            f"{result['f1_score']*100:>10.2f}%  {result['false_positive_rate']*100:>10.2f}%\n"
        )

    f.write("\n" + "=" * 110 + "\n")
    f.write("æœ€ä½³å‚æ•°è¯¦æƒ…\n")
    f.write("=" * 110 + "\n")
    best = all_results[0]
    f.write(f"distance_threshold_method2 = {best['distance_threshold']:.2f}\n")
    f.write(f"n_neighbors = {best['n_neighbors']}\n")
    f.write(f"\næ€§èƒ½æŒ‡æ ‡:\n")
    f.write(f"  å¬å›ç‡: {best['recall']*100:.2f}%\n")
    f.write(f"  ç²¾ç¡®ç‡: {best['precision']*100:.2f}%\n")
    f.write(f"  F1-Score: {best['f1_score']*100:.2f}%\n")
    f.write(f"  è¯¯æŠ¥ç‡: {best['false_positive_rate']*100:.2f}%\n")
    f.write(f"  ç»¼åˆè¯„åˆ†: {best['score']:.4f}\n")

print(f"\nå®Œæ•´ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

print("\n" + "=" * 110)
print("ğŸ’¡ æç¤º:")
print("=" * 110)
print("å¦‚æœä½ æƒ³ä½¿ç”¨ä¸åŒçš„è¯„åˆ†å…¬å¼é‡æ–°è¯„ä¼°å‚æ•°ï¼Œå¯ä»¥è¿è¡Œ:")
print("  python grad_sdf/dataset/rescore-params.py")
print("\nåœ¨ rescore-params.py ä¸­ä¿®æ”¹ custom_score() å‡½æ•°æ¥å®šä¹‰ä½ çš„è¯„åˆ†å…¬å¼")
print(f"åŸå§‹æ•°æ®å·²ä¿å­˜åœ¨: {json_output_file}")
